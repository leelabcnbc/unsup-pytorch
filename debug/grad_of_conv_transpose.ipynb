{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook shows the gradient of conv transpose, at least in simple cases (stride=1, no padding).\n",
    "\n",
    "here we have no bias; adding it won't change the result, as bias doesn't affect gradient of weights at all by simple derivation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import FloatTensor\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.functional import mse_loss, conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import ConvTranspose2d, Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channel_code = 4\n",
    "kernel_size = 9\n",
    "input_this = FloatTensor(1, num_channel_code, 17, 17)\n",
    "_ = input_this.normal_(0, 1)\n",
    "output_ref = FloatTensor(1, 1, 25, 25)\n",
    "_ = output_ref.normal_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward():\n",
    "    code_to_image_layer = ConvTranspose2d(num_channel_code, 1, kernel_size, bias=False)\n",
    "    input_var = Variable(input_this, requires_grad=True)\n",
    "    output_now = code_to_image_layer(input_var)\n",
    "    cost = mse_loss(output_now, Variable(output_ref), size_average=False)\n",
    "#     return cost\n",
    "    if input_var.grad is not None:\n",
    "        input_var.grad.zero()\n",
    "    # then compute grad.\n",
    "    cost.backward()\n",
    "    return cost.data.numpy()[0], input_var.grad.data.numpy(), code_to_image_layer, output_now.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_this, grad_this, layer_forward, output_this = forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656.59412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0020146435, 0.62366945)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_this.mean(), grad_this.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 9, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok. let's try to recover this myself.\n",
    "layer_forward.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward():\n",
    "    # ok. let's compute the grad \n",
    "    grad1 = 2*(output_this-output_ref)\n",
    "    \n",
    "    grad2 = conv2d(Variable(FloatTensor(grad1), volatile=True),\n",
    "                   layer_forward.weight,bias=None)\n",
    "    print(grad2.size())\n",
    "    return grad2.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 17, 17])\n"
     ]
    }
   ],
   "source": [
    "grad_this_hand = backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "assert grad_this.shape == grad_this_hand.shape == (1,num_channel_code,17,17)\n",
    "print(abs(grad_this-grad_this_hand).max())\n",
    "assert abs(grad_this-grad_this_hand).max() < 1e-4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
